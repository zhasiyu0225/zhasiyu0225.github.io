---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I'm Yujia Liu, an HCI student researcher passionate about Human-AI Interaction and Affective Computing. Currently, I'm pursuing my M.A. in Information Art and Design at the Future Lab of Tsinghua University, under the advisory of Prof. [Yingqing Xu](https://thfl.tsinghua.edu.cn/en/yjdw/yjtd/xyq/index.htm) and Prof. [Chun Yu](https://pi.cs.tsinghua.edu.cn/lab/people/ChunYu/). 

My academic journey began with undergraduate degrees in Automation Engineering and Industrial Design, laying a dual foundation that marries technical precision with aesthetic innovation. My work embodies this cross-disciplinary fusion, particularly evident in projects ranging from AR-enhanced smart mirrors, LLM-based digital well-being management, to 3D LEGO design generations. Each project reflects my commitment to leveraging a blend of engineering precision and design sensitivity, aiming to create technologies that are not only efficient and functional but also accessible and engaging for users.

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">In submission to UIST 2024</div><img src='images/proj/mirrorcle.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[3D-Mirrorcle: Bridging the Virtual and Real through Depth Alignment in Smart Mirror Systems](https://arxiv.org/pdf/2310.13617.pdf)

**Yujia Liu**, Qi Xin, Chenzhuo Xiang, Yu Zhang, Yingqing Xu.
- In submission to the ACM Symposium on User Interface Software and Technology (UIST), 2024.
- TLDR: An innovative smart mirror system integrating AR with real-world reflections, addressing depth disparity via a lenticular grating setup, with real-time image adjustment and position adaptation algorithms to align AR content with the user's depth perception and enhance interaction realism. Demonstrated through a makeup application prototype with significant improvements in accuracy (11.1% ‚Üë), task completion time (47.9% ‚Üì), and user satisfaction (44.4% ‚Üë) compared to the existing systems.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2024</div><img src='images/proj/mindshift.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention](https://arxiv.org/pdf/2309.16639.pdf)

Ruolan Wu, Chun Yu, Xiaole Pan, **Yujia Liu**, Ningning Zhang, Yue Fu, Yuhan Wang, Zhi Zheng, Li Chen, Qi-aolei Jiang, Xuhai Xu, Yuanchun Shi.
- To appear in the 2024 CHI Conference on Human Factors in Computing Systems (CHI), 2024.
- TLDR: A mobile application that leverages LLMs for generating dynamic, personalized persuasive content to mitigate problematic smartphone use for digital well-being. Effectiveness validated via a 5-week field trial with 25 participants, showing significant improvements in intervention acceptance (17.8-22.5% ‚Üë) and reductions in smartphone usage frequency (12.1-14.4% ‚Üì).
</div>
</div>

# üóÇÔ∏è Projects 

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/lego.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**3D LEGO Designs Generation and Structural Optimization with Generative Models**
- TLDR: A 3D model generation system combining generative models, stability prediction, and optimization to repurpose unused LEGO bricks, fostering creativity and sustainability. Achieved up to a 30% increase in user engagement, a 40% increase in design diversity, and a 35% improvement in user satisfaction, demonstrating significant advances in interactive design and sustainability.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/music.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Adaptive Music and Lighting Systems for Emotional Well-being**
- TLDR: A smart home system that dynamically adjusts music and lighting to nurture inhabitants' emotional well-being, leveraging environmental and color psychology with MER. Capable of responding to and anticipating user emotions and preferences, with a 30% enhancement in well-being and a 25% increase in satisfaction according to a user experience study.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Automated Video Editing with Semantic Analysis and Aesthetic Evaluation**
- TLDR: An intelligent video editing framework that integrates video semantic analysis and aesthetic evaluation to com-bine AI with user-centered designs for automating video production tasks. Achieved a 40% reduction in editing time and a 25% increase in viewer engagement, demonstrating the frame-work's effectiveness in improving editing efficiency and output quality.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/phone_color.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**A Comprehensive Study of Color Preferences Across Diverse Displays**
- TLDR: Collected color preferences in digital media via a comprehensive user survey with 89 participants and an expert interview with 24 photographers to identify color preferences across image types & user demographics. Developed a system based on DeepLPF for adaptive image color enhancement under mobile photography scenar-ios, significantly enhanced user satisfaction (12% ‚Üë) in an offline evaluation with 89 participants.
</div>
</div>

# üìñ Educations
- *2022.09 - Now*, Tsinghua University, M.A. in Information Art and Design.
- *2017.08 - 2022.07*, Tsinghua University, B.Eng. in Automation Engineering & B.A. in Industrial Design.

# üíª Internships
- *2022.10 - Now*, Research Assistant @ Tsinghua University Pervasive Interaction Laboratory.
- *2021.07 - 2021.10*, Product Manager Intern @ Huawei, ID/UX Design Group, Cyberverse Product Line.
- *2020.06 - 2020.08*, Algorithm Engineer Intern @ Beijing Ewaybot Technology, Robot Navigation Group.

